{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f514048",
   "metadata": {},
   "source": [
    "- Se debe generar en aws un bash con el script de python que se desea ejecutar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e2ff77",
   "metadata": {},
   "source": [
    "- Después, mediante ssh se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7de0a",
   "metadata": {},
   "source": [
    "<center> ssh -i Deliveryrobotpassword.pem ubuntu@18.116.62.44 \"bash ~/bash_test.sh\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "903599e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script_to_send_images_and_get_tflite_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 'script_to_send_images_and_get_tflite_model.py'\n",
    "\n",
    "import paramiko\n",
    "from scp import SCPClient\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "def create_SSH_Client(host, port, user, password_name, password_path):\n",
    "    client = paramiko.SSHClient()\n",
    "    client.load_system_host_keys()\n",
    "    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    client.connect(host, port, user, password_name, key_filename=password_path)\n",
    "    return client\n",
    "\n",
    "ip_servidor = \"3.142.240.64\"\n",
    "ruta_clave = \"../../../proyectos_ai/delivery_robot/Deliveryrobotpassword.pem\"\n",
    "\n",
    "while True:\n",
    "    fecha = datetime.now()\n",
    "    if fecha.hour == 15:\n",
    "        #print(\"Entrando\")\n",
    "        #se cargan las imaǵenes al servidor\n",
    "        ssh = create_SSH_Client(ip_servidor, 22, \"ubuntu\",\"Deliveryrobotpassword.pem\", ruta_clave)\n",
    "        scp = SCPClient(ssh.get_transport())\n",
    "        scp.put('../Images', recursive=True,\n",
    "                remote_path='/home/ubuntu/delivery_robot_project/static/')\n",
    "        #se cierra la conexión al terminar\n",
    "        ssh.close()\n",
    "        #se ejecuta el script en aws que permite reentrenar el modelo de tensorflow\n",
    "        # y genera un nuevo modelo en tensorflowlite\n",
    "        os.system('ssh -i '+ruta_clave+' ubuntu@'+ip_servidor+' \"sudo bash /home/ubuntu/bash_entrenar.sh\"')\n",
    "        \n",
    "        #Después de entrenador y generado el tflite en el servidor, nos traemos el .tflite para que\n",
    "        #funcione en la interfaz de tkinter\n",
    "        os.system('scp -i '+ruta_clave+' ubuntu@'+ip_servidor+':~/delivery_robot_project/static/model_tflite_'+str(fecha.month)+'_'+str(fecha.day)+'.tflite'+' ../data/')\n",
    "        #se eliminan las imágenes del servidor\n",
    "        break\n",
    "        time.sleep(60*60) #se para la ejecución por una hora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1c20f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"script_to_send_images_and_get_tflite_model.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17550026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12d01171",
   "metadata": {},
   "source": [
    "### script para entrenar el modelo en aws\n",
    "- este script se ejecuta en aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de17d1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script_para_entrenar_en_aws.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"script_para_entrenar_en_aws.py\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "batch_size = 64\n",
    "img_height = 145\n",
    "img_width = 145\n",
    "data_root='./Images'\n",
    "print(\"datos de entrenamiento\")\n",
    "data_train = tf.keras.preprocessing.image_dataset_from_directory(str(data_root),\n",
    "                                                               seed=123,\n",
    "                                                               image_size=(img_height, img_width),\n",
    "                                                               batch_size=batch_size,\n",
    "                                                               label_mode='categorical')\n",
    "\n",
    "#definimos el model_augmentation que transforma las imágenes de entrada\n",
    "model_augmentation = tf.keras.Sequential(name=\"augmentation_model\")\n",
    "model_augmentation.add(tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"))\n",
    "model_augmentation.add(tf.keras.layers.experimental.preprocessing.RandomRotation(.1, fill_mode=\"constant\"))\n",
    "model_augmentation.add(tf.keras.layers.experimental.preprocessing.RandomZoom(.2, fill_mode=\"constant\"))\n",
    "#mapeamos los datos de entrada\n",
    "map_data_train = data_train.map(lambda x, y: (model_augmentation(x), y))\n",
    "#cargamos el modelo entrenado\n",
    "modelo_entrenado = tf.keras.models.load_model(\"./models_finalversionmap15.0version145x145\")\n",
    "#entrenamos el modelo\n",
    "hist_model = modelo_entrenado.fit(map_data_train, epochs=10)\n",
    "#guardamos un json que contiene el historial de entrenamiento\n",
    "open(\"./resultados_entrenamiento.json\", \"w\").write(json.dumps(hist_model.history))\n",
    "#gurdamos el modelo entrenado\n",
    "#por ahora no sobreescribimos el modelo, lo guardamos con el mes y el dia\n",
    "fecha = datetime.now()\n",
    "modelo_entrenado.save(\"./modelo_reentrenado_\"+str(fecha.month)+\"_\"+str(fecha.day))\n",
    "#generamos el modelo en formato tensorflowlite a partir del modelo reentrenado\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(modelo_entrenado)\n",
    "tflite = converter.convert()\n",
    "#guardamos el modelo de tensorflowlite (tambien por mes y dia)\n",
    "open(\"./model_tflite_\"+str(fecha.month)+\"_\"+str(fecha.day)+\".tflite\", \"wb\").write(tflite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fba82b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639be0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c9554a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f0b7be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_servidor = \"3.142.240.64\"\n",
    "ruta_clave = \"../../../proyectos_ai/delivery_robot/Deliveryrobotpassword.pem\"\n",
    "\n",
    "os.system('ssh -i '+ruta_clave+' ubuntu@'+ip_servidor+' \"sudo bash /home/ubuntu/bash_entrenar.sh\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de16d08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('scp -i '+ruta_clave+' ubuntu@'+ip_servidor+':~/delivery_robot_project/static/model_tflite_'+str(fecha.month)+'_'+str(fecha.day)+'.tflite'+' ./')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
