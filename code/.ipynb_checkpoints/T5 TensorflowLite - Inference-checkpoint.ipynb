{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ccb474b",
   "metadata": {},
   "source": [
    "### Autor\n",
    "- Nombre: Edwin Jahir Rueda Rojas\n",
    "- email: ejrueda95g@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70ff3eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd5c85",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "- El objetivo de este notebook es transformar un modelo entrenado en tensorflow a un modelo de tensorflowLite, y mediante inferencia poder hacer predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8687906b",
   "metadata": {},
   "source": [
    "- Utilizamos el modelo basado en transfer learning entrenado en los notebooks anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19db9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model using TFLiteConverter\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"../models_aug/\")\n",
    "tflite_model = converter.convert()\n",
    "with open(\"../model_tflite.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b306c31",
   "metadata": {},
   "source": [
    "- ahora usamos un interprete de tensorflowLite para poder cargar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec763045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"../model_tflite.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6bfd290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'serving_default_rescaling_input:0',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 100, 100,   3], dtype=int32),\n",
       "  'shape_signature': array([ -1, 100, 100,   3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e1dd49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 53,\n",
       "  'shape': array([ 1, 11], dtype=int32),\n",
       "  'shape_signature': array([-1, 11], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88beb57c",
   "metadata": {},
   "source": [
    "### probamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f5a856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (1, 100, 100, 3)\n",
      "[[1.0406003e-06 8.0313530e-06 8.7719894e-07 9.1642392e-01 4.6086745e-05\n",
      "  3.8679736e-06 2.1434648e-06 7.8685241e-07 8.3415605e-02 8.7948240e-05\n",
      "  9.6952408e-06]]\n"
     ]
    }
   ],
   "source": [
    "input_shape = input_details[0]['shape']\n",
    "input_image = PIL.Image.open(\"../data/archive/raw-img/farfalla/OIP--v_vx0B7J5lpKWjLjknadQAAAA.jpeg\").resize((100,100), PIL.Image.BICUBIC)\n",
    "image_arr = np.expand_dims(np.array(input_image, dtype=np.float32), axis=0)\n",
    "print(\"input shape:\", image_arr.shape)\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], image_arr)\n",
    "#se invoca el interprete para que haga la predicci√≥n\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8d8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d764d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82012bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
